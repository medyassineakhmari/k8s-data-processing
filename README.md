# Infrastructure Kubernetes - SystÃ¨me de Traitement de DonnÃ©es en Temps RÃ©el

## ğŸ“‹ Vue d'ensemble

Ce projet dÃ©ploie une infrastructure complÃ¨te de traitement de donnÃ©es en temps rÃ©el sur Kubernetes avec autoscaling automatique basÃ© sur la charge.

### Architecture

```
Data Stream â†’ RabbitMQ â†’ Spark (auto-scaled) â†’ MongoDB
                              â†“
                        Swagger API
```

### Composants

- **RabbitMQ**: File de messages pour l'ingestion en temps rÃ©el
- **Spark**: Traitement des donnÃ©es (avec autoscaling KEDA)
- **MongoDB**: Base de donnÃ©es (ReplicaSet 3 nodes)
- **Swagger API**: Exposition des rÃ©sultats
- **KEDA**: Autoscaling basÃ© sur la queue RabbitMQ
- **Prometheus + Grafana**: Monitoring

---

## ğŸš€ Installation Initiale

### PrÃ©requis

- Cluster Kubernetes (v1.24+)
- kubectl configurÃ©
- Helm 3
- Docker (pour builder les images)

### 1. Cloner le repository

```bash
git clone (https://github.com/medyassineakhmari/k8s-data-processing.git)
cd k8s-data-processing
```

### 2. Configurer les secrets

**IMPORTANT**: Avant le dÃ©ploiement, modifie les mots de passe dans `secrets/mongodb-secret.yaml`

```bash
# GÃ©nÃ©rer un mot de passe base64
echo -n "ton_nouveau_password" | base64
```

Remplace les valeurs dans le fichier secret.

### 4. DÃ©ployer l'infrastructure

```bash
chmod +x scripts/*.sh
./scripts/deploy.sh
```
---


## ğŸ¯ Autoscaling KEDA

### Configuration actuelle

Le ScaledObject KEDA scale Spark selon:
- **Queue Length**: > 10 messages par replica â†’ scale up
- **CPU**: > 70% â†’ scale up
- **Memory**: > 80% â†’ scale up

### Limites

- **Min replicas**: 1
- **Max replicas**: 10
- **Scale up**: Rapide (15s)
- **Scale down**: Progressif (60s cooldown)

### Modifier les rÃ¨gles de scaling

Ã‰dite `keda/spark-scaledobject.yaml` puis:

```bash
kubectl apply -f keda/spark-scaledobject.yaml
```
---
## ğŸ“Œ Utilisation du Makefile

Ce projet inclut un **Makefile** qui facilite la gestion de l'infrastructure Kubernetes et des diffÃ©rents composants du systÃ¨me de traitement de donnÃ©es.  
Au lieu de taper des commandes `kubectl`, `docker` ou dâ€™exÃ©cuter des scripts sÃ©parÃ©ment, le Makefile centralise tout et **rÃ©duit la complexitÃ©**.

### Commandes principales

DÃ©ployer lâ€™infrastructure complÃ¨te :

```bash
make deploy
```

Voir les logs des composants :

```bash
make logs-spark   # Affiche les logs des pods Spark
make logs-api     # Affiche les logs de lâ€™API Swagger
```

VÃ©rifier le status des pods et services :

```bash
make status
```

Voir toutes les commandes disponibles dans le Makefile :

```bash
make help
```
---
