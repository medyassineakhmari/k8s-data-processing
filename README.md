# Infrastructure Kubernetes - SystÃ¨me de Traitement de DonnÃ©es en Temps RÃ©el

## ðŸ“‹ Vue d'ensemble

Ce projet dÃ©ploie une infrastructure complÃ¨te de traitement de donnÃ©es en temps rÃ©el sur Kubernetes avec autoscaling automatique basÃ© sur la charge.

### Architecture

```
Data Stream â†’ RabbitMQ â†’ Spark (auto-scaled) â†’ MongoDB
                              â†“
                        Swagger API
```

### Composants

- **RabbitMQ**: File de messages pour l'ingestion en temps rÃ©el
- **Spark**: Traitement des donnÃ©es (avec autoscaling KEDA)
- **MongoDB**: Base de donnÃ©es (ReplicaSet 3 nodes)
- **Swagger API**: Exposition des rÃ©sultats
- **KEDA**: Autoscaling basÃ© sur la queue RabbitMQ
- **Prometheus + Grafana**: Monitoring

---

## ðŸš€ Installation Initiale

### PrÃ©requis

- Cluster Kubernetes (v1.24+)
- kubectl configurÃ©
- Helm 3
- Docker (pour builder les images)

### 1. Cloner le repository

```bash
git clone (https://github.com/medyassineakhmari/k8s-data-processing.git)
cd k8s-data-processing
```

### 2. Configurer les secrets

**IMPORTANT**: Avant le dÃ©ploiement, modifie les mots de passe dans `secrets/mongodb-secret.yaml`

```bash
# GÃ©nÃ©rer un mot de passe base64
echo -n "ton_nouveau_password" | base64
```

Remplace les valeurs dans le fichier secret.

### 4. DÃ©ployer l'infrastructure

```bash
chmod +x scripts/*.sh
./scripts/deploy.sh
```
---


## ðŸŽ¯ Autoscaling KEDA

### Configuration actuelle

Le ScaledObject KEDA scale Spark selon:
- **Queue Length**: > 10 messages par replica â†’ scale up
- **CPU**: > 70% â†’ scale up
- **Memory**: > 80% â†’ scale up

### Limites

- **Min replicas**: 1
- **Max replicas**: 10
- **Scale up**: Rapide (15s)
- **Scale down**: Progressif (60s cooldown)

### Modifier les rÃ¨gles de scaling

Ã‰dite `keda/spark-scaledobject.yaml` puis:

```bash
kubectl apply -f keda/spark-scaledobject.yaml
```
---

---

**CrÃ©Ã© pour le projet de systÃ¨me distribuÃ© - Ã‰quipe DevOps** ðŸš€
