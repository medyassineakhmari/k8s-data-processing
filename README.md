# Infrastructure Kubernetes - SystÃ¨me de Traitement de DonnÃ©es en Temps RÃ©el

## ğŸ“‹ Vue d'ensemble

Ce projet dÃ©ploie une infrastructure complÃ¨te de traitement de donnÃ©es en temps rÃ©el sur Kubernetes avec autoscaling automatique basÃ© sur la charge.

### Architecture

```
Data Stream â†’ RabbitMQ â†’ Spark (auto-scaled) â†’ MongoDB
                              â†“
                        Swagger API
```

### Composants

- **RabbitMQ**: File de messages pour l'ingestion en temps rÃ©el
- **Spark**: Traitement des donnÃ©es (avec autoscaling KEDA)
- **MongoDB**: Base de donnÃ©es (ReplicaSet 3 nodes)
- **Swagger API**: Exposition des rÃ©sultats
- **KEDA**: Autoscaling basÃ© sur la queue RabbitMQ
- **Prometheus + Grafana**: Monitoring

---

## ğŸš€ Installation Initiale

### PrÃ©requis

- Cluster Kubernetes (v1.24+)
- kubectl configurÃ©
- Helm 3
- Docker (pour builder les images)

### 1. Cloner le repository

```bash
git clone <votre-repo>
cd k8s-data-processing
```

### 2. Configurer les secrets

**IMPORTANT**: Avant le dÃ©ploiement, modifie les mots de passe dans `secrets/mongodb-secret.yaml`

```bash
# GÃ©nÃ©rer un mot de passe base64
echo -n "ton_nouveau_password" | base64
```

Remplace les valeurs dans le fichier secret.

### 3. Adapter la configuration

Modifie ces fichiers selon ton environnement:

- `storage/*.yaml`: Ajuste le `storageClassName` selon ton cluster
- `api/swagger-ingress.yaml`: Change le domaine `api.your-domain.com`
- `spark/spark-deployment.yaml`: Remplace `your-registry/spark-processor:latest`
- `api/swagger-deployment.yaml`: Remplace `your-registry/swagger-api:latest`

### 4. DÃ©ployer l'infrastructure

```bash
chmod +x scripts/*.sh
./scripts/deploy.sh
```

Le script va:
1. âœ… CrÃ©er le namespace `data-processing`
2. âœ… DÃ©ployer RabbitMQ (StatefulSet)
3. âœ… DÃ©ployer MongoDB (ReplicaSet 3 nodes)
4. âœ… DÃ©ployer Spark (avec autoscaling)
5. âœ… DÃ©ployer l'API Swagger
6. âœ… Installer KEDA pour l'autoscaling
7. âœ… Configurer le monitoring

---

## ğŸ”„ Workflow de Mise Ã  Jour

### Quand tes collÃ¨gues modifient le code Spark

```bash
# 1. Tes collÃ¨gues commitent leur code
cd spark_app/
git add .
git commit -m "feat: amÃ©lioration du traitement"
git push

# 2. Builder la nouvelle image Docker
cd docker/spark/
docker build -t your-registry/spark-processor:v1.2.0 .
docker push your-registry/spark-processor:v1.2.0

# 3. DÃ©ployer la nouvelle version
cd ../../
./scripts/update.sh spark v1.2.0
```

### Quand tes collÃ¨gues modifient l'API

```bash
# 1. Commit des changements
cd api_app/
git commit -m "fix: correction endpoint"
git push

# 2. Builder l'image
cd docker/api/
docker build -t your-registry/swagger-api:v1.3.0 .
docker push your-registry/swagger-api:v1.3.0

# 3. DÃ©ployer
./scripts/update.sh api v1.3.0
```

### Mise Ã  jour automatique avec CI/CD

Si tu configures GitHub Actions (fichier fourni):

1. Tes collÃ¨gues push sur `main`
2. GitHub Actions build automatiquement les images
3. Les deployments Kubernetes sont mis Ã  jour automatiquement
4. Rollback automatique en cas d'Ã©chec

---

## ğŸ”™ Rollback en cas de problÃ¨me

```bash
# Voir l'historique des dÃ©ploiements
kubectl rollout history deployment/spark-processor -n data-processing

# Revenir Ã  la version prÃ©cÃ©dente
./scripts/rollback.sh spark

# Ou revenir Ã  une version spÃ©cifique
./scripts/rollback.sh spark 3
```

---

## ğŸ“Š Monitoring et ObservabilitÃ©

### AccÃ©der Ã  Grafana

```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
```

Ouvrir: http://localhost:3000
- Username: `admin`
- Password: `admin123`

### AccÃ©der Ã  Prometheus

```bash
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
```

Ouvrir: http://localhost:9090

### Voir les logs

```bash
# Logs Spark
kubectl logs -f -n data-processing -l app=spark-processor

# Logs API
kubectl logs -f -n data-processing -l app=swagger-api

# Logs RabbitMQ
kubectl logs -f -n data-processing -l app=rabbitmq
```

### MÃ©triques importantes Ã  surveiller

- **RabbitMQ**: `rabbitmq_queue_messages_ready` (messages en attente)
- **Spark**: Nombre de pods actifs, temps de traitement
- **MongoDB**: Connexions actives, utilisation disque
- **KEDA**: Ã‰vÃ©nements de scaling

---

## ğŸ¯ Autoscaling KEDA

### Configuration actuelle

Le ScaledObject KEDA scale Spark selon:
- **Queue Length**: > 10 messages par replica â†’ scale up
- **CPU**: > 70% â†’ scale up
- **Memory**: > 80% â†’ scale up

### Limites

- **Min replicas**: 1
- **Max replicas**: 10
- **Scale up**: Rapide (15s)
- **Scale down**: Progressif (60s cooldown)

### Modifier les rÃ¨gles de scaling

Ã‰dite `keda/spark-scaledobject.yaml` puis:

```bash
kubectl apply -f keda/spark-scaledobject.yaml
```

### Tester l'autoscaling

```bash
# Injecter beaucoup de messages dans RabbitMQ
# Tu devrais voir les pods Spark se multiplier

kubectl get pods -n data-processing -w
kubectl get scaledobject -n data-processing
```

---

## ğŸ› Troubleshooting

### ProblÃ¨me: Pods en CrashLoopBackOff

```bash
# Voir les logs dÃ©taillÃ©s
kubectl describe pod <pod-name> -n data-processing
kubectl logs <pod-name> -n data-processing --previous

# VÃ©rifier les events
kubectl get events -n data-processing --sort-by='.lastTimestamp'
```

### ProblÃ¨me: RabbitMQ ne dÃ©marre pas

```bash
# VÃ©rifier le PVC
kubectl get pvc -n data-processing

# VÃ©rifier les logs
kubectl logs rabbitmq-0 -n data-processing

# Forcer la suppression et recrÃ©ation
kubectl delete statefulset rabbitmq -n data-processing
kubectl apply -f rabbitmq/rabbitmq-statefulset.yaml
```

### ProblÃ¨me: MongoDB ReplicaSet ne se forme pas

```bash
# VÃ©rifier les pods
kubectl get pods -l app=mongodb -n data-processing

# Se connecter Ã  un pod et vÃ©rifier le RS
kubectl exec -it mongodb-0 -n data-processing -- mongosh
rs.status()
```

### ProblÃ¨me: Images ne se tÃ©lÃ©chargent pas

```bash
# VÃ©rifier les secrets de registry (si registry privÃ©)
kubectl create secret docker-registry regcred \
  --docker-server=<your-registry> \
  --docker-username=<username> \
  --docker-password=<password> \
  -n data-processing

# Ajouter imagePullSecrets dans les deployments
```

---

## ğŸ“ Structure du Projet

```
k8s-data-processing/
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ namespace.yaml                     # Namespace principal
â”œâ”€â”€ configmaps/
â”‚   â”œâ”€â”€ rabbitmq-config.yaml          # Config RabbitMQ
â”‚   â””â”€â”€ spark-config.yaml             # Config Spark
â”œâ”€â”€ secrets/
â”‚   â””â”€â”€ mongodb-secret.yaml           # Secrets (passwords)
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ rabbitmq-pvc.yaml             # Storage RabbitMQ
â”‚   â””â”€â”€ mongodb-pvc.yaml              # Storage MongoDB
â”œâ”€â”€ rabbitmq/
â”‚   â”œâ”€â”€ rabbitmq-statefulset.yaml     # DÃ©ploiement RabbitMQ
â”‚   â””â”€â”€ rabbitmq-service.yaml         # Service RabbitMQ
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ spark-serviceaccount.yaml     # RBAC Spark
â”‚   â”œâ”€â”€ spark-deployment.yaml         # DÃ©ploiement Spark
â”‚   â””â”€â”€ spark-service.yaml            # Service Spark
â”œâ”€â”€ mongodb/
â”‚   â”œâ”€â”€ mongodb-statefulset.yaml      # DÃ©ploiement MongoDB
â”‚   â””â”€â”€ mongodb-service.yaml          # Service MongoDB
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ swagger-deployment.yaml       # DÃ©ploiement API
â”‚   â”œâ”€â”€ swagger-service.yaml          # Service API
â”‚   â””â”€â”€ swagger-ingress.yaml          # Ingress API
â”œâ”€â”€ keda/
â”‚   â”œâ”€â”€ keda-install.sh               # Installation KEDA
â”‚   â””â”€â”€ spark-scaledobject.yaml       # Config autoscaling
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ install.sh                # Installation Prometheus
â”‚   â””â”€â”€ servicemonitors.yaml          # Monitors pour metrics
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â””â”€â”€ Dockerfile                # Image Spark
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ Dockerfile                # Image API
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh                     # DÃ©ploiement complet
â”‚   â”œâ”€â”€ update.sh                     # Mise Ã  jour composants
â”‚   â””â”€â”€ rollback.sh                   # Rollback versions
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ deploy.yml                # CI/CD GitHub Actions
```

---

## ğŸ” SÃ©curitÃ©

### Secrets Ã  ne JAMAIS commiter

- `secrets/mongodb-secret.yaml` (contient les passwords)
- Fichiers `.kubeconfig`
- ClÃ©s privÃ©es

Utilise `.gitignore`:

```gitignore
secrets/*.yaml
*.kubeconfig
*.key
*.pem
```

### Bonnes pratiques

1. âœ… Utilise des secrets Kubernetes, pas des variables en dur
2. âœ… Active RBAC sur ton cluster
3. âœ… Limite les ressources CPU/Memory pour Ã©viter le resource exhaustion
4. âœ… Utilise NetworkPolicies pour isoler les pods
5. âœ… Active TLS sur l'Ingress (certificats Let's Encrypt)

---

## ğŸ“ Pour tes collÃ¨gues dÃ©veloppeurs

### Structure du code Spark attendue

```python
# spark_app/main.py
from pyspark.sql import SparkSession
import pika
from pymongo import MongoClient

# CrÃ©er SparkSession
spark = SparkSession.builder \
    .appName("DataProcessor") \
    .getOrCreate()

# Connecter Ã  RabbitMQ
connection = pika.BlockingConnection(
    pika.ConnectionParameters(
        host=os.getenv('RABBITMQ_HOST'),
        credentials=pika.PlainCredentials(
            os.getenv('RABBITMQ_USERNAME'),
            os.getenv('RABBITMQ_PASSWORD')
        )
    )
)

# Traiter les donnÃ©es...
# Sauvegarder dans MongoDB...
```

### Structure de l'API attendue

```python
# api_app/main.py
from fastapi import FastAPI
from pymongo import MongoClient

app = FastAPI()

# Connecter Ã  MongoDB
client = MongoClient(
    host=os.getenv('MONGODB_HOST'),
    username=os.getenv('MONGODB_USERNAME'),
    password=os.getenv('MONGODB_PASSWORD')
)

@app.get("/health")
def health():
    return {"status": "healthy"}

@app.get("/data")
def get_data():
    # RÃ©cupÃ©rer les donnÃ©es depuis MongoDB
    pass
```

---

## ğŸ“ Support

### En cas de problÃ¨me

1. VÃ©rifier les logs: `kubectl logs -f <pod> -n data-processing`
2. VÃ©rifier les events: `kubectl get events -n data-processing`
3. VÃ©rifier le status: `kubectl get pods -n data-processing`
4. Consulter ce README

### Ressources utiles

- [Documentation Kubernetes](https://kubernetes.io/docs/)
- [Documentation KEDA](https://keda.sh/docs/)
- [Documentation Spark](https://spark.apache.org/docs/latest/)
- [Documentation RabbitMQ](https://www.rabbitmq.com/documentation.html)

---

## âœ… Checklist avant production

- [ ] Changer tous les passwords par dÃ©faut
- [ ] Configurer les backups MongoDB
- [ ] Activer TLS sur tous les services
- [ ] Configurer les NetworkPolicies
- [ ] Mettre en place les alertes Prometheus
- [ ] Tester le rollback
- [ ] Documenter les procÃ©dures d'urgence
- [ ] Configurer les resource quotas
- [ ] Tester l'autoscaling sous charge
- [ ] Valider la stratÃ©gie de backup

---

**CrÃ©Ã© pour le projet de systÃ¨me distribuÃ© - Ã‰quipe DevOps** ğŸš€
