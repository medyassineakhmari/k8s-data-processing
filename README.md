# Infrastructure Kubernetes - Syst√®me de Traitement de Donn√©es en Temps R√©el

## üìã Vue d'ensemble

Ce projet d√©ploie une infrastructure compl√®te de traitement de donn√©es en temps r√©el sur Kubernetes avec autoscaling automatique bas√© sur la charge.

### Architecture

```
Data Stream ‚Üí RabbitMQ ‚Üí Spark (auto-scaled) ‚Üí MongoDB
                              ‚Üì
                        Swagger API
```

### Composants

- **RabbitMQ**: File de messages pour l'ingestion en temps r√©el
- **Spark**: Traitement des donn√©es (avec autoscaling KEDA)
- **MongoDB**: Base de donn√©es (ReplicaSet 3 nodes)
- **Swagger API**: Exposition des r√©sultats
- **KEDA**: Autoscaling bas√© sur la queue RabbitMQ
- **Prometheus + Grafana**: Monitoring

---

## üöÄ Installation Initiale

### Pr√©requis

- Cluster Kubernetes (v1.24+)
- kubectl configur√©
- Helm 3
- Docker (pour builder les images)

### 1. Cloner le repository

```bash
git clone (https://github.com/medyassineakhmari/k8s-data-processing.git)
cd k8s-data-processing
```

### 2. Configurer les secrets

**IMPORTANT**: Avant le d√©ploiement, modifie les mots de passe dans `secrets/mongodb-secret.yaml`

```bash
# G√©n√©rer un mot de passe base64
echo -n "ton_nouveau_password" | base64
```

Remplace les valeurs dans le fichier secret.

### 4. D√©ployer l'infrastructure

```bash
chmod +x scripts/*.sh
./scripts/deploy.sh
```
---


## üéØ Autoscaling KEDA

### Configuration actuelle

Le ScaledObject KEDA scale Spark selon:
- **Queue Length**: > 10 messages par replica ‚Üí scale up
- **CPU**: > 70% ‚Üí scale up
- **Memory**: > 80% ‚Üí scale up

### Limites

- **Min replicas**: 1
- **Max replicas**: 10
- **Scale up**: Rapide (15s)
- **Scale down**: Progressif (60s cooldown)

### Modifier les r√®gles de scaling

√âdite `keda/spark-scaledobject.yaml` puis:

```bash
kubectl apply -f keda/spark-scaledobject.yaml
```
---
## üìå Utilisation du Makefile

Ce projet inclut un **Makefile** qui facilite la gestion de l'infrastructure Kubernetes et des diff√©rents composants du syst√®me de traitement de donn√©es.  
Au lieu de taper des commandes `kubectl`, `docker` ou d‚Äôex√©cuter des scripts s√©par√©ment, le Makefile centralise tout et **r√©duit la complexit√©**, ce qui permet √† l'√©quipe de d√©ployer, monitorer et mettre √† jour le projet plus rapidement et de mani√®re plus fiable.

### Commandes principales

D√©ployer l‚Äôinfrastructure compl√®te :

```bash
make deploy

Voir les logs des composants :

make logs-spark   # Affiche les logs des pods Spark
make logs-api     # Affiche les logs de l‚ÄôAPI Swagger

V√©rifier le status des pods et services :

make status

Acc√©der rapidement aux services via port-forward :

make forward-api        # API Swagger sur localhost:8080
make forward-rabbitmq   # Interface RabbitMQ sur localhost:15672
make forward-grafana    # Grafana sur localhost:3000

Voir toutes les commandes disponibles dans le Makefile :

make help
