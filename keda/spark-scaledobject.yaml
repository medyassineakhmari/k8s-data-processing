apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: spark-processor-scaler
  namespace: data-processing
spec:
  scaleTargetRef:
    name: spark-processor  # Le deployment Spark à scaler
  minReplicaCount: 1  # Minimum de pods
  maxReplicaCount: 10  # Maximum de pods
  pollingInterval: 15  # Vérifier toutes les 15 secondes
  cooldownPeriod: 60  # Attendre 60s avant de scale down
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 120  # Stabiliser avant scale down
          policies:
          - type: Percent
            value: 50  # Réduire de max 50% à la fois
            periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 0  # Scale up immédiatement
          policies:
          - type: Percent
            value: 100  # Doubler si nécessaire
            periodSeconds: 15
          - type: Pods
            value: 4  # Ou ajouter 4 pods
            periodSeconds: 15
          selectPolicy: Max  # Prendre la valeur max
  triggers:
  - type: rabbitmq
    metadata:
      host: amqp://admin:rabbitpass123@rabbitmq.data-processing.svc.cluster.local:5672/  # Connection string
      protocol: auto
      mode: QueueLength  # Scaler basé sur la longueur de la queue
      value: "10"  # Scale si > 10 messages par replica
      queueName: data-stream  # Nom de ta queue RabbitMQ
      useRegex: "false"
  - type: cpu
    metricType: Utilization
    metadata:
      value: "70"  # Scale si CPU > 70%
  - type: memory
    metricType: Utilization
    metadata:
      value: "80"  # Scale si Memory > 80%
